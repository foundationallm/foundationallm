<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
      <title>Image Description | FoundationaLLM </title>
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      <meta name="title" content="Image Description | FoundationaLLM ">
      
      
      <link rel="icon" href="../../../../../media/favicon.ico">
      <link rel="stylesheet" href="../../../../../public/docfx.min.css">
      <link rel="stylesheet" href="../../../../../public/main.css">
      <meta name="docfx:navrel" content="../../../../../toc.html">
      <meta name="docfx:tocrel" content="../../../../toc.html">
      
      <meta name="docfx:rel" content="../../../../../">
      
      
      <meta name="docfx:docurl" content="https://github.com/foundationallm/foundationallm/blob/main/docs/docs/management-portal/how-to-guides/data/knowledge-sources/image-description.md/#L1">
      <meta name="loc:inThisArticle" content="In this article">
      <meta name="loc:searchResultsCount" content="{count} results for &quot;{query}&quot;">
      <meta name="loc:searchNoResults" content="No results for &quot;{query}&quot;">
      <meta name="loc:tocFilter" content="Filter by title">
      <meta name="loc:nextArticle" content="Next">
      <meta name="loc:prevArticle" content="Previous">
      <meta name="loc:themeLight" content="Light">
      <meta name="loc:themeDark" content="Dark">
      <meta name="loc:themeAuto" content="Auto">
      <meta name="loc:changeTheme" content="Change theme">
      <meta name="loc:copy" content="Copy">
      <meta name="loc:downloadPdf" content="Download PDF">

      <script type="module" src="./../../../../../public/docfx.min.js"></script>

      <script>
        const theme = localStorage.getItem('theme') || 'auto'
        document.documentElement.setAttribute('data-bs-theme', theme === 'auto' ? (window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light') : theme)
      </script>

  </head>

  <body class="tex2jax_ignore" data-layout="" data-yaml-mime="">
    <header class="bg-body border-bottom">
      <nav id="autocollapse" class="navbar navbar-expand-md" role="navigation">
        <div class="container-xxl flex-nowrap">
          <a class="navbar-brand" href="../../../../../index.html">
            <img id="logo" class="svg" src="../../../../../media/fllm-icon-50x50.svg" alt="FoundationaLLM">
            FoundationaLLM
          </a>
          <button class="btn btn-lg d-md-none border-0" type="button" data-bs-toggle="collapse" data-bs-target="#navpanel" aria-controls="navpanel" aria-expanded="false" aria-label="Toggle navigation">
            <i class="bi bi-three-dots"></i>
          </button>
          <div class="collapse navbar-collapse" id="navpanel">
            <div id="navbar">
              <form class="search" role="search" id="search">
                <i class="bi bi-search"></i>
                <input class="form-control" id="search-query" type="search" disabled placeholder="Search" autocomplete="off" aria-label="Search">
              </form>
            </div>
          </div>
        </div>
      </nav>
    </header>

    <main class="container-xxl">
      <div class="toc-offcanvas">
        <div class="offcanvas-md offcanvas-start" tabindex="-1" id="tocOffcanvas" aria-labelledby="tocOffcanvasLabel">
          <div class="offcanvas-header">
            <h5 class="offcanvas-title" id="tocOffcanvasLabel">Table of Contents</h5>
            <button type="button" class="btn-close" data-bs-dismiss="offcanvas" data-bs-target="#tocOffcanvas" aria-label="Close"></button>
          </div>
          <div class="offcanvas-body">
            <nav class="toc" id="toc"></nav>
          </div>
        </div>
      </div>

      <div class="content">
        <div class="actionbar">
          <button class="btn btn-lg border-0 d-md-none" type="button" data-bs-toggle="offcanvas" data-bs-target="#tocOffcanvas" aria-controls="tocOffcanvas" aria-expanded="false" aria-label="Show table of contents">
            <i class="bi bi-list"></i>
          </button>

          <nav id="breadcrumb"></nav>
        </div>

        <article data-uid="">
<h1 id="image-description">Image Description</h1>

<p>Learn about LLM-generated image description capabilities for processing visual content in FoundationaLLM.</p>
<h2 id="overview">Overview</h2>
<p>FoundationaLLM leverages Large Language Models (LLMs) with vision capabilities to process images, extract textual content, and generate rich descriptions. This makes visual content searchable and accessible to agents, enabling knowledge retrieval from image-based documents.</p>
<h2 id="llm-generated-image-descriptions">LLM-Generated Image Descriptions</h2>
<p>FoundationaLLM uses vision-capable LLMs to analyze images and generate detailed textual descriptions. These descriptions:</p>
<ul>
<li>Are generated using models like GPT-4 Vision or Claude Vision</li>
<li>Can describe image content up to the model's context window limits</li>
<li>Are stored as searchable text in your knowledge base</li>
<li>Enable semantic search across visual content</li>
</ul>
<h3 id="description-quality-factors">Description Quality Factors</h3>
<table>
<thead>
<tr>
<th>Factor</th>
<th>Impact</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Model Size</strong></td>
<td>Larger models produce more detailed, accurate descriptions</td>
</tr>
<tr>
<td><strong>Token Allocation</strong></td>
<td>More tokens allow longer, richer descriptions</td>
</tr>
<tr>
<td><strong>Image Resolution</strong></td>
<td>Higher resolution enables finer detail recognition</td>
</tr>
<tr>
<td><strong>Image Complexity</strong></td>
<td>Simple images are described more accurately</td>
</tr>
</tbody>
</table>
<h2 id="capabilities">Capabilities</h2>
<table>
<thead>
<tr>
<th>Capability</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>OCR (Optical Character Recognition)</strong></td>
<td>Extract text visible in images</td>
</tr>
<tr>
<td><strong>LLM Image Description</strong></td>
<td>Generate natural language descriptions using vision models</td>
</tr>
<tr>
<td><strong>Visual Q&amp;A</strong></td>
<td>Answer questions about image content</td>
</tr>
<tr>
<td><strong>Content Summarization</strong></td>
<td>Create concise summaries of complex visual content</td>
</tr>
</tbody>
</table>
<h2 id="supported-image-formats">Supported Image Formats</h2>
<table>
<thead>
<tr>
<th>Format</th>
<th>Extension</th>
<th>Notes</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>JPEG</strong></td>
<td>.jpg, .jpeg</td>
<td>Most common photo format</td>
</tr>
<tr>
<td><strong>PNG</strong></td>
<td>.png</td>
<td>Supports transparency</td>
</tr>
<tr>
<td><strong>GIF</strong></td>
<td>.gif</td>
<td>Static images only</td>
</tr>
<tr>
<td><strong>BMP</strong></td>
<td>.bmp</td>
<td>Uncompressed bitmap</td>
</tr>
<tr>
<td><strong>TIFF</strong></td>
<td>.tiff, .tif</td>
<td>High-quality images</td>
</tr>
<tr>
<td><strong>WebP</strong></td>
<td>.webp</td>
<td>Modern web format</td>
</tr>
</tbody>
</table>
<h2 id="use-cases">Use Cases</h2>
<h3 id="document-processing">Document Processing</h3>
<ul>
<li><strong>Scanned Documents</strong>: Extract text from scanned PDFs and images</li>
<li><strong>Forms</strong>: Process filled-out forms and extract field values</li>
<li><strong>Receipts/Invoices</strong>: Digitize paper documents</li>
</ul>
<h3 id="visual-content-indexing">Visual Content Indexing</h3>
<ul>
<li><strong>Diagrams</strong>: Make technical diagrams searchable</li>
<li><strong>Charts</strong>: Extract data from chart images</li>
<li><strong>Screenshots</strong>: Index screenshot content</li>
</ul>
<h3 id="accessibility">Accessibility</h3>
<ul>
<li><strong>Alt Text Generation</strong>: Create descriptions for accessibility</li>
<li><strong>Image Cataloging</strong>: Describe and categorize image libraries</li>
</ul>
<h2 id="configuration">Configuration</h2>
<h3 id="prerequisites">Prerequisites</h3>
<ul>
<li>A vision-capable AI model configured (e.g., GPT-4 Vision, Claude Vision)</li>
<li>Data pipeline with image processing stages</li>
</ul>
<h3 id="data-pipeline-configuration">Data Pipeline Configuration</h3>
<p>To process images in a data pipeline:</p>
<ol>
<li><strong>Create or Edit a Data Pipeline</strong></li>
<li><strong>Select a Text Extraction Plugin</strong> that supports images</li>
<li><strong>Configure Vision Model</strong> for image processing</li>
<li><strong>Set Quality Parameters</strong>:</li>
</ol>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Detail Level</strong></td>
<td>Low, medium, or high detail extraction</td>
</tr>
<tr>
<td><strong>Max Tokens</strong></td>
<td>Token limit for generated descriptions</td>
</tr>
</tbody>
</table>
<h3 id="stage-configuration">Stage Configuration</h3>
<blockquote>
<p><strong>TODO</strong>: Document specific image processing stage configuration options in data pipelines.</p>
</blockquote>
<h2 id="model-considerations">Model Considerations</h2>
<h3 id="token-limits-and-model-size">Token Limits and Model Size</h3>
<p>Image processing consumes tokens from your AI model allocation. The quality and length of generated descriptions depends on your model configuration:</p>
<table>
<thead>
<tr>
<th>Model Tier</th>
<th>Typical Token Limit</th>
<th>Description Quality</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>GPT-4 Vision</strong></td>
<td>Up to 128K tokens</td>
<td>Highly detailed, comprehensive descriptions</td>
</tr>
<tr>
<td><strong>GPT-4o</strong></td>
<td>Up to 128K tokens</td>
<td>Fast, accurate descriptions</td>
</tr>
<tr>
<td><strong>Claude 3 Vision</strong></td>
<td>Up to 200K tokens</td>
<td>Extended context for complex images</td>
</tr>
</tbody>
</table>
<p><strong>Key considerations:</strong></p>
<ul>
<li>Higher detail levels use more tokens per image</li>
<li>Large images may require resizing before processing</li>
<li>Batch processing can optimize throughput</li>
<li>Token limits apply to both input (image) and output (description)</li>
</ul>
<h3 id="model-capabilities">Model Capabilities</h3>
<table>
<thead>
<tr>
<th>Model</th>
<th>OCR</th>
<th>Description</th>
<th>Analysis</th>
<th>Max Image Size</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>GPT-4 Vision</strong></td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
<td>20MB</td>
</tr>
<tr>
<td><strong>GPT-4o</strong></td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
<td>20MB</td>
</tr>
<tr>
<td><strong>Claude 3 Vision</strong></td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
<td>20MB</td>
</tr>
</tbody>
</table>
<blockquote>
<p><strong>Note</strong>: Actual limits depend on your specific model deployment configuration. Contact your administrator for deployment-specific limits.</p>
</blockquote>
<h3 id="resolution-considerations">Resolution Considerations</h3>
<table>
<thead>
<tr>
<th>Resolution</th>
<th>Processing</th>
<th>Quality</th>
<th>Cost</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Low</strong></td>
<td>Fast</td>
<td>Basic</td>
<td>Lower</td>
</tr>
<tr>
<td><strong>Medium</strong></td>
<td>Moderate</td>
<td>Good</td>
<td>Medium</td>
</tr>
<tr>
<td><strong>High</strong></td>
<td>Slower</td>
<td>Best</td>
<td>Higher</td>
</tr>
</tbody>
</table>
<h2 id="best-practices">Best Practices</h2>
<h3 id="image-quality">Image Quality</h3>
<ul>
<li>Use high-resolution images when text extraction is critical</li>
<li>Ensure good contrast between text and background</li>
<li>Avoid heavily compressed images</li>
</ul>
<h3 id="processing-optimization">Processing Optimization</h3>
<ul>
<li>Batch similar images together</li>
<li>Use appropriate detail levels for your use case</li>
<li>Consider preprocessing (cropping, enhancement) for poor quality sources</li>
</ul>
<h3 id="content-organization">Content Organization</h3>
<ul>
<li>Store images with meaningful filenames</li>
<li>Group related images in folders</li>
<li>Include metadata when available</li>
</ul>
<h2 id="integration-with-agents">Integration with Agents</h2>
<p>After processing, image content becomes available to agents through:</p>
<ol>
<li><strong>Vector Search</strong>: Descriptions are embedded and searchable</li>
<li><strong>Direct Analysis</strong>: Vision-capable agents can analyze images directly</li>
<li><strong>Contextual Answers</strong>: Agents can reference image content in responses</li>
</ol>
<h2 id="limitations">Limitations</h2>
<table>
<thead>
<tr>
<th>Limitation</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Handwriting</strong></td>
<td>Variable quality depending on legibility</td>
</tr>
<tr>
<td><strong>Complex Layouts</strong></td>
<td>Tables and forms may need specialized processing</td>
</tr>
<tr>
<td><strong>Image Quality</strong></td>
<td>Poor quality reduces extraction accuracy</td>
</tr>
<tr>
<td><strong>Language Support</strong></td>
<td>OCR accuracy varies by language</td>
</tr>
</tbody>
</table>
<h2 id="troubleshooting">Troubleshooting</h2>
<h3 id="poor-ocr-results">Poor OCR Results</h3>
<ul>
<li>Check image quality and resolution</li>
<li>Ensure text has good contrast</li>
<li>Consider preprocessing to enhance clarity</li>
</ul>
<h3 id="missing-descriptions">Missing Descriptions</h3>
<ul>
<li>Verify vision model is properly configured</li>
<li>Check pipeline stage configuration</li>
<li>Review model token limits</li>
</ul>
<h3 id="processing-failures">Processing Failures</h3>
<ul>
<li>Check image format is supported</li>
<li>Verify image isn't corrupted</li>
<li>Review size limits for your deployment</li>
</ul>
<h2 id="related-topics">Related Topics</h2>
<ul>
<li><a href="../data-pipelines/creating-data-pipelines.html">Creating Data Pipelines</a></li>
<li><a href="../data-sources.html">Data Sources</a></li>
<li><a href="../../models-endpoints/ai-models.html">AI Models Configuration</a></li>
</ul>

</article>


        <div class="next-article d-print-none border-top" id="nextArticle"></div>

      </div>

      <div class="affix">
        <nav id="affix"></nav>
      </div>
    </main>

    <div class="container-xxl search-results" id="search-results"></div>

    <footer class="border-top text-secondary">
      <div class="container-xxl">
        <div class="flex-fill">
          © FoundationaLLM. All rights reserved. | Find out more about FoundationaLLM at <a href="https://foundationallm.ai">foundationallm.ai</a>.
        </div>
      </div>
    </footer>
  </body>
</html>
