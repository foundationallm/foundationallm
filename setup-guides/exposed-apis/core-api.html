<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
      <title>Core API | FoundationaLLM </title>
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      <meta name="title" content="Core API | FoundationaLLM ">
      
      
      <link rel="icon" href="../../media/favicon.ico">
      <link rel="stylesheet" href="../../public/docfx.min.css">
      <link rel="stylesheet" href="../../public/main.css">
      <meta name="docfx:navrel" content="../../toc.html">
      <meta name="docfx:tocrel" content="../../toc.html">
      
      <meta name="docfx:rel" content="../../">
      
      
      <meta name="docfx:docurl" content="https://github.com/solliancenet/foundationallm/blob/main/docs/setup-guides/exposed-apis/core-api.md/#L1">
      <meta name="loc:inThisArticle" content="In this article">
      <meta name="loc:searchResultsCount" content="{count} results for &quot;{query}&quot;">
      <meta name="loc:searchNoResults" content="No results for &quot;{query}&quot;">
      <meta name="loc:tocFilter" content="Filter by title">
      <meta name="loc:nextArticle" content="Next">
      <meta name="loc:prevArticle" content="Previous">
      <meta name="loc:themeLight" content="Light">
      <meta name="loc:themeDark" content="Dark">
      <meta name="loc:themeAuto" content="Auto">
      <meta name="loc:changeTheme" content="Change theme">
      <meta name="loc:copy" content="Copy">
      <meta name="loc:downloadPdf" content="Download PDF">

      <script type="module" src="./../../public/docfx.min.js"></script>

      <script>
        const theme = localStorage.getItem('theme') || 'auto'
        document.documentElement.setAttribute('data-bs-theme', theme === 'auto' ? (window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light') : theme)
      </script>

  </head>

  <body class="tex2jax_ignore" data-layout="" data-yaml-mime="">
    <header class="bg-body border-bottom">
      <nav id="autocollapse" class="navbar navbar-expand-md" role="navigation">
        <div class="container-xxl flex-nowrap">
          <a class="navbar-brand" href="../../index.html">
            <img id="logo" class="svg" src="../../media/fllm-icon.svg" alt="FoundationaLLM">
            FoundationaLLM
          </a>
          <button class="btn btn-lg d-md-none border-0" type="button" data-bs-toggle="collapse" data-bs-target="#navpanel" aria-controls="navpanel" aria-expanded="false" aria-label="Toggle navigation">
            <i class="bi bi-three-dots"></i>
          </button>
          <div class="collapse navbar-collapse" id="navpanel">
            <div id="navbar">
              <form class="search" role="search" id="search">
                <i class="bi bi-search"></i>
                <input class="form-control" id="search-query" type="search" disabled placeholder="Search" autocomplete="off" aria-label="Search">
              </form>
            </div>
          </div>
        </div>
      </nav>
    </header>

    <main class="container-xxl">

      <div class="content">
        <div class="actionbar">

          <nav id="breadcrumb"></nav>
        </div>

        <article data-uid="">
<h1 id="core-api">Core API</h1>

<p>The Core API serves as the entry point for user requests to FoundationaLLM's underlying engine. While clients primarily interact with the Core API through the Chat UI, the Core API exposes some convenient interfaces for developers.</p>
<h2 id="sessionless-completion">Sessionless Completion</h2>
<p>The sessionless completion endpoint enables users to query agents without first creating a chat session.</p>
<p><strong>Endpoint:</strong> <code>[DEPLOYMENT URL]/core/orchestration/completion?api-version=1.0</code></p>
<blockquote>
<p><strong>Note:</strong> For AKS deployments, <code>[DEPLOYMENT URL]</code> is the same as the cluster FQDN, while for ACA deployments, the Core API endpoint can be found by navigating to the <code>[DEPLOYMENT PREFIX]coreca</code> Container App in the Azure Portal.</p>
</blockquote>
<p><strong>Sample Request:</strong></p>
<pre><code class="lang-json">{
    &quot;user_prompt&quot;: &quot;What are your capabilities?&quot;,
    &quot;settings&quot;: {
        &quot;agent_name&quot;: &quot;internal-context&quot;,
        &quot;model_parameters&quot;: {
            &quot;temperature&quot;: 0.4,
            &quot;deployment_name&quot;: &quot;completions&quot;,
            &quot;top_k&quot;: 5,
            &quot;top_p&quot;: 0.9,
            &quot;do_sample&quot;: true,
            &quot;max_new_tokens&quot;: 100,
            &quot;return_full_text&quot;: true,
            &quot;ignore_eos&quot;: true
        },
        &quot;agent_parameters&quot;: {
            &quot;index_filter_expression&quot;: &quot;search.ismatch('FoundationaLLM', 'Text')&quot;,
            &quot;index_top_n&quot;: 5
        }
    }
}
</code></pre>
<div class="NOTE">
<h5>Note</h5>
<p>The <code>settings</code> object provides to override various parameters at runtime, and is optional. Within <code>settings</code> both <code>model_parameters</code> and <code>settings.agent_parameters</code> (along with their members) are optional. If not provided, the Core API will use the default model and agent settings.</p>
</div>
<p><strong>model_parameters:</strong>
| Name | Type | Description |
| ---- | ---- | ----------- |
| <code>temperature</code> | <code>float</code> | Controls randomness. Lowering the temperature means that the model will produce more repetitive and deterministic responses. Increasing the temperature will result in more unexpected or creative responses. Try adjusting temperature or Top P but not both. This value should be a float between 0.0 and 1.0. |
| <code>deployment_name</code> | <code>string</code> | The deployment name for the language model. |
| <code>top_k</code> | <code>int</code> | The number of highest probability vocabulary tokens to keep for top-k-filtering. Default value is null, which disables top-k-filtering. |
| <code>top_p</code> | <code>float</code> | The cumulative probability of parameter highest probability vocabulary tokens to keep for nucleus sampling. Top P (or Top Probabilities) is imilar to temperature, this controls randomness but uses a different method. Lowering Top P will narrow the model’s token selection to likelier tokens. Increasing Top P will let the model choose from tokens with both high and low likelihood. Try adjusting temperature or Top P but not both. |
| <code>do_sample</code> | <code>bool</code> | Whether or not to use sampling; use greedy decoding otherwise. |
| <code>max_new_tokens</code> | <code>int</code> | Sets a limit on the number of tokens per model response. The API supports a maximum of number of tokens (depending on the deployment) shared between the prompt (including system message, examples, message history, and user query) and the model's response. One token is roughly 4 characters for typical English text. |
| <code>return_full_text</code> | <code>bool</code> | Whether or not to return the full text (prompt + response) or only the generated part (response). Default value is false. |
| <code>ignore_eos</code> | <code>bool</code> | Whether to ignore the End of Sequence(EOS) token and continue generating tokens after the EOS token is generated. Defaults to False. |</p>
<p><strong>agent_parameters:</strong>
| Name | Type | Description |
| ---- | ---- | ----------- |
| <code>index_filter_expression</code> | <code>string</code> | This value should be a string representing the search filter expression to limit documents to be searched by the index retriever |
| <code>index_top_n</code> | <code>int</code> | Controls the number of search results to return from an index for prompt augmentation. |</p>
<p><strong>Payload Headers:</strong></p>
<table>
<thead>
<tr>
<th>Header</th>
<th>Value</th>
<th>Details</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Authorization</code></td>
<td><code>Bearer [ENTRA ID BEARER TOKEN]</code></td>
<td>Valid token from Entra ID</td>
</tr>
<tr>
<td><code>Content-Type</code></td>
<td><code>application/json</code></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Sample Response:</strong></p>
<pre><code class="lang-json">{
    &quot;text&quot;: &quot;FoundationaLLM is a copilot platform that simplifies and streamlines building knowledge management and analytic agents over the data sources present across your enterprise. It provides integration with enterprise data sources used by agents for in-context learning, fine-grain security controls over data used by agents, and pre/post completion filters that guard against attack. The solution is scalable and load balances across multiple endpoints. It is also extensible to new data sources, new LLM orchestrators, and LLMs. You can learn more about FoundationaLLM at https://foundationallm.ai.&quot;
}
</code></pre>
<p><strong>Sample Postman Request:</strong> <code>/orchestration/completion/Requests a completion from the downstream APIs.</code></p>

</article>

        <div class="contribution d-print-none">
          <a href="https://github.com/solliancenet/foundationallm/blob/main/docs/setup-guides/exposed-apis/core-api.md/#L1" class="edit-link">Edit this page</a>
        </div>

        <div class="next-article d-print-none border-top" id="nextArticle"></div>

      </div>

      <div class="affix">
        <nav id="affix"></nav>
      </div>
    </main>

    <div class="container-xxl search-results" id="search-results"></div>

    <footer class="border-top text-secondary">
      <div class="container-xxl">
        <div class="flex-fill">
          © FoundationaLLM. All rights reserved. | Find out more about FoundationaLLM at <a href="https://foundationallm.ai">foundationallm.ai</a>.
        </div>
      </div>
    </footer>
  </body>
</html>
